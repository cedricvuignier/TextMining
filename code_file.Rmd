---
title: "code_prof"
author: "Cédric Vuignier"
date: "12/4/2020"
output:
  rmdformats::readthedown:
    code_folding: hide
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	eval = FALSE
)
```

# INTRO

### literature importante

- clean the tweet : https://towardsdatascience.com/text-mining-with-r-gathering-and-cleaning-data-8f8b0d65e67c 
- set your twitter API : https://www.infoworld.com/article/3515712/how-to-search-twitter-with-rtweet-and-r.html  
- scrapp by hashtag or region or user : https://cran.r-project.org/web/packages/rtweet/vignettes/intro.html 

### connect to API twitter

only run this now if the point 2 is not done yet. 
twitter log-in (need to register the account in the pop-up windows)
name : textmining13
mdp : textmining2020

```{r message=FALSE, warning=FALSE, eval=FALSE}
library(rtweet)
get_token()

```

 no need to run the following code if you have already done this part. 
 follow the instruction to link your twitter app with your R CONSOL. Do it only once. 
```{r message=FALSE, warning=FALSE, eval=FALSE}
## load rtweet
library(rtweet)

## store api keys (these are fake example values; replace with your own keys)
api_key <- "cFRZi4lsJGD4DxrtLT24za5UH"
api_secret_key <- "iHBlU1fA5WdQ17N3udi8FWg8TlwugXb8e6c34MNRGmKXNJFIQY"

## authenticate via web browser
token <- create_token(
  app = "TextMiningHEC",
  consumer_key = api_key,
  consumer_secret = api_secret_key)

#verify it

#token
```

# Tweet scrcapping

### Get the tweets
We collect the 3000 last tweets from TRUMP, JOE BIDEN, KAMALA HARRIS, MIKE PENCE. the DF has 90 variable. It's way too much. 

Twitter sets a limit of 3200 tweets per request. So we have to do the same operation for each account (@).
```{r message=FALSE, warning=FALSE, eval=FALSE}
#split the scrapping into two part to avoid the limit 

#REPUCLICAN
tweet_trump <- get_timelines("realDonaldTrump", n = 3000, include_rts = FALSE)

#vice president tweet
tweet_VP <- get_timelines("VP", n = 3000, include_rts = TRUE)


#get the hastag trump
tweet_trump_hashtag <- search_tweets(
  "#Trump", n = 3000, include_rts = FALSE
)



#########DEMOCRATE#############################

tweet_BIDEN <- get_timelines("JoeBiden", n = 3000, 
            include_rts = FALSE)

#get the hastage biden
tweet_biden_hashtag <- search_tweets(
  "#Biden", n = 3000, include_rts = FALSE
)

#the vice president selected by biden if he is elected 
tweet_KAMALA <- get_timelines("KamalaHarris", n = 3000, 
            include_rts = FALSE)

#obama
tweet_OBAMA <- get_timelines("BarackObama", n = 3000, 
            include_rts = FALSE)       

#Alexandria Ocasio-Cortez
tweet_ACO <- get_timelines("AOC", n = 3000, 
            include_rts = FALSE)    
```

# creation of the corpus

### similarities, VSM, CLUSERING

j'ai créé 2 corpus
- avant / après
- un seul avec tous les tweets
```{r}
# trump analysis
TRUMP_all_tweet <- read_csv("data supervised_L/trump_after.csv")

#get only the tweets after the election
Trump_after_analysis <- TRUMP_all_tweet %>% 
  mutate(date = date(created_at)) %>% filter(date >= "2020-11-03", 
                                             display_text_width > 100)
#get the tweet before
Trump_before_analysis <- TRUMP_all_tweet %>% 
  mutate(date = date(created_at)) %>% filter(date < "2020-11-03", 
                                             display_text_width > 100)
#add variable before or after
Trump_after_analysis <-Trump_after_analysis %>% 
  mutate(when = "after")
Trump_before_analysis <-Trump_before_analysis %>% 
  mutate(when = "before")
#############

#book of tweets "after" 
Trump_after_analysis <- Trump_after_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(Trump_after_analysis$text, collapse = '. ')) 

Trump_after_analysis <- rename(Trump_after_analysis, text = `paste(Trump_after_analysis$text, collapse = ". ")`)
#book of tweets "before"  
Trump_before_analysis <- Trump_before_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(Trump_before_analysis$text, collapse = '. ')) 

Trump_before_analysis <- rename(Trump_before_analysis, text = `paste(Trump_before_analysis$text, collapse = ". ")`)


# vp analysis
vp_all_tweet <- read_csv("data supervised_L/vp_after.csv")
#get only the tweets after the election
vp_after_analysis <- vp_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date >= "2020-11-03",
        display_text_width > 100)
#get the tweet before
vp_before_analysis <- vp_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date < "2020-11-03",
        display_text_width > 100)
#add variable before or after
vp_after_analysis <-vp_after_analysis %>% 
  mutate(when = "after")

vp_before_analysis <-vp_before_analysis %>% 
  mutate(when = "before")
#############
vp_after_analysis <- vp_after_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(vp_after_analysis$text, collapse = '. ')) 

vp_after_analysis <- rename(vp_after_analysis, text = `paste(vp_after_analysis$text, collapse = ". ")`)
  
vp_before_analysis <- vp_before_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(vp_before_analysis$text, collapse = '. ')) 

vp_before_analysis <- rename(vp_before_analysis, text = `paste(vp_before_analysis$text, collapse = ". ")`)

# biden analysis
biden_all_tweet <- read_csv("data supervised_L/biden_after.csv")
#get only the tweets after the election
biden_after_analysis <- biden_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date >= "2020-11-03",
        display_text_width > 100)
#get the tweet before
biden_before_analysis <- biden_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date < "2020-11-03",
        display_text_width > 100)
#add variable before or after
biden_after_analysis <-biden_after_analysis %>% 
  mutate(when = "after")

biden_before_analysis <-biden_before_analysis %>% 
  mutate(when = "before")
#############
biden_after_analysis <- biden_after_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(biden_after_analysis$text, collapse = '. ')) 

biden_after_analysis <- rename(biden_after_analysis, text = `paste(biden_after_analysis$text, collapse = ". ")`)
  
biden_before_analysis <- biden_before_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(biden_before_analysis$text, collapse = '. ')) 

biden_before_analysis <- rename(biden_before_analysis, text = `paste(biden_before_analysis$text, collapse = ". ")`)

# kamala analysis
kamala_all_tweet <- read_csv("data supervised_L/kamala_after.csv")
#get only the tweets after the election
kamala_after_analysis <- kamala_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date >= "2020-11-03",
        display_text_width > 100)
#get the tweet before
kamala_before_analysis <- kamala_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date < "2020-11-03",
        display_text_width > 100)
#add variable before or after
kamala_after_analysis <-kamala_after_analysis %>% 
  mutate(when = "after")

kamala_before_analysis <-kamala_before_analysis %>% 
  mutate(when = "before")
#############
kamala_after_analysis <- kamala_after_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(kamala_after_analysis$text, collapse = '. ')) 

kamala_after_analysis <- rename(kamala_after_analysis, text = `paste(kamala_after_analysis$text, collapse = ". ")`)
  
kamala_before_analysis <- kamala_before_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(kamala_before_analysis$text, collapse = '. ')) 

kamala_before_analysis <- rename(kamala_before_analysis, text = `paste(kamala_before_analysis$text, collapse = ". ")`)

# obama analysis
obama_all_tweet <- read_csv("data supervised_L/obama_after.csv")
#get only the tweets after the election
obama_after_analysis <- obama_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date >= "2020-11-03",
        display_text_width > 100)
#get the tweet before
obama_before_analysis <- obama_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date < "2020-11-03",
        display_text_width > 100)
#add variable before or after
obama_after_analysis <-obama_after_analysis %>% 
  mutate(when = "after")

obama_before_analysis <-obama_before_analysis %>% 
  mutate(when = "before")
#############
obama_after_analysis <- obama_after_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(obama_after_analysis$text, collapse = '. ')) 

obama_after_analysis <- rename(obama_after_analysis, text = `paste(obama_after_analysis$text, collapse = ". ")`)
  
obama_before_analysis <- obama_before_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(obama_before_analysis$text, collapse = '. ')) 

obama_before_analysis <- rename(obama_before_analysis, text = `paste(obama_before_analysis$text, collapse = ". ")`)


# AOC analysis
aoc_all_tweet <- read_csv("data supervised_L/aoc_after.csv")
#get only the tweets after the election
aoc_after_analysis <- aoc_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date >= "2020-11-03",
        display_text_width > 100)
#get the tweet before
aoc_before_analysis <- aoc_all_tweet %>% 
  mutate(date = date(created_at)) %>% 
  filter(date < "2020-11-03",
        display_text_width > 100)
#add variable before or after
aoc_after_analysis <-aoc_after_analysis %>% 
  mutate(when = "after")

aoc_before_analysis <-aoc_before_analysis %>% 
  mutate(when = "before")
#############
aoc_after_analysis <- aoc_after_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(aoc_after_analysis$text, collapse = '. ')) 

aoc_after_analysis <- rename(aoc_after_analysis, text = `paste(aoc_after_analysis$text, collapse = ". ")`)
  
aoc_before_analysis <- aoc_before_analysis %>% 
  select(text,screen_name, when) %>% 
  group_by(screen_name, when) %>% 
  summarise(paste(aoc_before_analysis$text, collapse = '. ')) 

aoc_before_analysis <- rename(aoc_before_analysis, text = `paste(aoc_before_analysis$text, collapse = ". ")`)

corpus <- rbind(Trump_after_analysis, Trump_before_analysis, vp_after_analysis, vp_before_analysis,
                biden_after_analysis, biden_before_analysis, kamala_after_analysis, kamala_before_analysis,
                obama_after_analysis, obama_before_analysis, aoc_after_analysis, aoc_before_analysis)
corpus <- corpus %>% mutate(Document=paste(when,"_",screen_name,sep="")) 

###
#creation du corpus
corpus = data.frame(lapply(corpus, as.character), stringsAsFactors=FALSE)

write.csv(corpus, "data supervised_L\\corpus.csv", row.names=FALSE)

```

### clean the corpus
I have seen many things qui vont pas et qu'on doit nettoyer 
```{r}
corpus <- read_csv("data supervised_L/corpus.csv")
corpus <- corpus %>% mutate(Document=paste(when,"_",screen_name,sep="")) 
# Set the text to lowercase
corpus$text <- tolower(corpus$text)
# Remove mentions, urls, emojis, numbers, punctuations, etc.
corpus$text <- gsub("@\\w+", "", corpus$text)
corpus$text <- gsub("\\d+\\w*\\d*", "", corpus$text)
corpus$text <- gsub("#\\w+", "", corpus$text)
corpus$text <- gsub("[^\x01-\x7F]", "", corpus$text)
corpus$text <- gsub("[[:punct:]]", " ", corpus$text)


corpus_final = data.frame(lapply(corpus, as.character), stringsAsFactors=FALSE)

write.csv(corpus_final, "data supervised_L\\corpus_final_before_after.csv", row.names=FALSE)
```

### GLOBAL CORPUS 

```{r}
# trump analysis
TRUMP_all_tweet <- read_csv("data supervised_L/trump_after.csv")

TRUMP_all_tweet <- TRUMP_all_tweet %>% 
  select(text,screen_name) %>% 
  group_by(screen_name) %>% 
  summarise(paste(TRUMP_all_tweet$text, collapse = ' ')) 

TRUMP_all_tweet <- rename(TRUMP_all_tweet, text = `paste(TRUMP_all_tweet$text, collapse = " ")`)

# vp analysis
vp_all_tweet <- read_csv("data supervised_L/vp_after.csv")

vp_all_tweet <- vp_all_tweet %>% 
  select(text,screen_name) %>% 
  group_by(screen_name) %>% 
  summarise(paste(vp_all_tweet$text, collapse = ' ')) 

vp_all_tweet <- rename(vp_all_tweet, text = `paste(vp_all_tweet$text, collapse = " ")`)

# biden analysis
biden_all_tweet <- read_csv("data supervised_L/biden_after.csv")

biden_all_tweet <- biden_all_tweet %>% 
  select(text,screen_name) %>% 
  group_by(screen_name) %>% 
  summarise(paste(biden_all_tweet$text, collapse = ' ')) 

biden_all_tweet <- rename(biden_all_tweet, text = `paste(biden_all_tweet$text, collapse = " ")`)
  
# kamala analysis
kamala_all_tweet <- read_csv("data supervised_L/kamala_after.csv")

kamala_all_tweet <- kamala_all_tweet %>% 
  select(text,screen_name) %>% 
  group_by(screen_name) %>% 
  summarise(paste(kamala_all_tweet$text, collapse = ' ')) 

kamala_all_tweet <- rename(kamala_all_tweet, text = `paste(kamala_all_tweet$text, collapse = " ")`)

# obama analysis
obama_all_tweet <- read_csv("data supervised_L/obama_after.csv")

obama_all_tweet <- obama_all_tweet %>% 
  select(text,screen_name) %>% 
  group_by(screen_name) %>% 
  summarise(paste(obama_all_tweet$text, collapse = ' ')) 

obama_all_tweet <- rename(obama_all_tweet, text = `paste(obama_all_tweet$text, collapse = " ")`)

# AOC analysis
aoc_all_tweet <- read_csv("data supervised_L/aoc_after.csv")

aoc_all_tweet <- aoc_all_tweet %>% 
  select(text,screen_name) %>% 
  group_by(screen_name) %>% 
  summarise(paste(aoc_all_tweet$text, collapse = ' ')) 

aoc_all_tweet <- rename(aoc_all_tweet, text = `paste(aoc_all_tweet$text, collapse = " ")`)

corpus_all <- rbind(TRUMP_all_tweet, vp_all_tweet, biden_all_tweet, kamala_all_tweet, obama_all_tweet, aoc_all_tweet)

###
#creation du corpus
corpus_all = data.frame(lapply(corpus_all, as.character), stringsAsFactors=FALSE)

write.csv(corpus_all, "data supervised_L\\corpus_final.csv", row.names=FALSE)

```

### clean the corpus
I have seen many things qui vont pas et qu'on doit nettoyer 
```{r}
corpus_final <- read_csv("data supervised_L/corpus_final.csv")
# Set the text to lowercase
corpus_final$text <- tolower(corpus_final$text)
# Remove mentions, urls, emojis, numbers, punctuations, etc.
corpus_final$text <- gsub("@\\w+", "", corpus_final$text)
corpus_final$text <- gsub("\\d+\\w*\\d*", "", corpus_final$text)
corpus_final$text <- gsub("#\\w+", "", corpus_final$text)
corpus_final$text <- gsub("[^\x01-\x7F]", "", corpus_final$text)
corpus_final$text <- gsub("[[:punct:]]", " ", corpus_final$text)


corpus_final = data.frame(lapply(corpus_final, as.character), stringsAsFactors=FALSE)

write.csv(corpus_final, "data supervised_L\\corpus_final.csv", row.names=FALSE)
```

# Sentiment analysis

```{r message=FALSE, warning=FALSE}

corpus_final_before_after <- read_csv("data supervised_L/corpus_final_before_after.csv")
corpus_final <- read_csv("data supervised_L/corpus_final.csv")

tweet.tb <- as_tibble(data.frame(corpus_final))
tweet.tok <- unnest_tokens(tweet.tb, output="word", input="text", to_lower=TRUE, strip_punct=TRUE, 
                           strip_numeric=TRUE)

tweet.sent <- tweet.tok %>%
  inner_join(get_sentiments("nrc"))

tweet.sent %>% group_by(screen_name, sentiment) %>% summarize(n = n()) %>% 
  ggplot(aes(x = sentiment, y = n, fill = sentiment)) + 
  geom_bar(stat = "identity", alpha = 0.8) + 
  facet_wrap(~ screen_name) + coord_flip()

tweet.sent %>% group_by(screen_name, sentiment) %>%  summarize(n = n()) %>% 
  mutate(freq = n / sum(n)) %>% ggplot(aes(x = sentiment, y = freq, fill = sentiment)) + 
  geom_bar(stat = "identity", alpha = 0.8) + 
  facet_wrap(~ screen_name) + coord_flip()

#the same but scale with the length

tweet.tb <- as_tibble(data.frame(corpus_final_before_after))
tweet.tok <- unnest_tokens(tweet.tb, output="word", input="text", to_lower=TRUE, strip_punct=TRUE, 
                           strip_numeric=TRUE)

tweet.sent <- tweet.tok %>%
  inner_join(get_sentiments("nrc"))

tweet.sent %>% group_by(Document, sentiment) %>%  summarize(n = n()) %>% 
  mutate(freq = n / sum(n)) %>% ggplot(aes(x = sentiment, y = freq, fill = sentiment)) + 
  geom_bar(stat = "identity", alpha = 0.8) + 
  facet_wrap(~ Document) + coord_flip()


```

### using "afinn"  - value based
```{r message=FALSE, warning=FALSE}
tweet.sent <- tweet.tok %>%
  inner_join(get_sentiments("afinn"))
## Summarize per document (value average) + barplot
aggregate(value~screen_name, data=tweet.sent, FUN=mean)


aggregate(value~screen_name, data=tweet.sent, FUN=mean) %>% 
  ggplot(aes(x = screen_name, y = value)) + 
  geom_bar(stat = "identity") + coord_flip()
######################before after#######################
tweet.tb <- as_tibble(data.frame(corpus_final_before_after))
tweet.tok <- unnest_tokens(tweet.tb, output="word", input="text", to_lower=TRUE, strip_punct=TRUE, 
                           strip_numeric=TRUE)

tweet.sent <- tweet.tok %>%
  inner_join(get_sentiments("afinn"))
## Summarize per document (value average) + barplot
aggregate(value~Document, data=tweet.sent, FUN=mean)


aggregate(value~Document, data=tweet.sent, FUN=mean) %>% 
  ggplot(aes(x = Document, y = value)) + 
  geom_bar(stat = "identity") + coord_flip()


```

### using valence shifter

not working with our data set 

```{r}
library(sentimentr)
library(lexicon)
corpus_final <- read_csv("data supervised_L/corpus_final.csv")

corpus_valence <- corpus_final %>% head(2)

tweet.text <- get_sentences(corpus_valence$text)
(tweet.senti <- sentiment(tweet.text))

tweet.senti <- as_tibble(tweet.senti)

tweet.senti %>% group_by(element_id) %>% 
  ggplot(aes(x = sentence_id, y = sentiment)) + 
  geom_line() + 
  facet_wrap(~ element_id) 
```

# similarities

### jaccard index
```{r message=FALSE, warning=FALSE}
corpus_final <- read_csv("data supervised_L/corpus_final_before_after.csv")


#create the TI-IDF matrix and remove some words 
tweet.cp <- corpus(corpus_final$text, corpus_final$Document)
tweet.tfidf <- dfm_tfidf(dfm(tweet.cp, remove_punct = TRUE, remove_numbers=TRUE, remove = c("u","polowczyk", "xdzz","dylan", "amp", "tune", "garland", "t","co", "https","gsfsgh","et", "http", "gsfsghkmdm", "eoxt", stopwords("english"))))
#jaccard index
TW_jacc <- textstat_simil(tweet.tfidf, method = "jaccard", margin = "documents")
#heatmap
TW.jac.mat <- melt(as.matrix(TW_jacc)) # Convert the object to matrix then to data frame 
ggplot(data = TW.jac.mat, aes(x=Var1, y=Var2, fill=value))+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0.5, limit = c(0,1), name="Jaccard")+
  geom_tile()
#clustering
TW_hc <- hclust(dist(1 - TW_jacc))
#plot
plot(TW_hc)
#explain the cluster
tweet.clust <- cutree(TW_hc, k=3)
tweet.clust <- as.data.frame(tweet.clust) %>% arrange(desc(tweet.clust))
tweet.clust%>% 
  kable(caption = "General statistics", col.names = c()) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = F,
    position = "left"
  )

#extract the most used words
tweet.clust <- cutree(TW_hc, k=3)
wordsclust <- data.frame(
  Clust.1 = names(sort(apply(tweet.tfidf[tweet.clust==1,],2,sum), decreasing = TRUE)[1:8]),
  Clust.2 = names(sort(apply(tweet.tfidf[tweet.clust==2,],2,sum), decreasing = TRUE)[1:8]),
  Clust.3 = names(sort(apply(tweet.tfidf[tweet.clust==3,],2,sum), decreasing = TRUE)[1:8])) 

wordsclust%>% 
  kable(caption = "clustering", col.names = c("cluster 1", "cluster 2", "cluster 3")) %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = F,
    position = "left"
  )
```

# Topic modeling

In this part, we use the database containing tweets from before and after the election day. When creating the corpus, we regroup all tweets from a politican in a same document. As we have six politicians, we have 6 documents in our corpus. 

We proceed to the cleaning of the corpus. 

```{r message=FALSE, warning=FALSE}
corpus_final <- read_csv("data supervised_L/corpus_final.csv")
corpus_final <- corpus(corpus_final$text, corpus_final$screen_name)
corpus_final <- gsub('\\b\\w{1,2}\\b','', corpus_final) #remove words whose length is smaller than 3

#start with 4 dim
library(quanteda)
library(quanteda.textmodels)
tweet.dfm <- dfm(corpus_final,
                 remove_punct = TRUE, 
                 remove_symbols = TRUE, 
                 remove_url = TRUE,
                 remove = stopwords("english"),
                 remove_numbers=TRUE)
```

### LSA

```{r message=FALSE, warning=FALSE}
# row.names.remove <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1")
# tweet.dfm <- tweet.dfm[!(row.names(tweet.dfm) %in% row.names.remove), ]

dimsetup <- textmodel_lsa(tweet.dfm, nd=4)

#analyze the correlation
ns <- apply(tweet.dfm, 1, sum) # row-sum of the DTM
plot(ns~dimsetup$docs[,1], xlab = "Dimension 1", ylab = "Document length", main = "Dimension 1 versus document lenght")
```

 using TF

```{r message=FALSE, warning=FALSE}

#plot dimensions 2 and 3 
x <- dimsetup$features[,2:3] %>% as.data.frame()
row.names.remove <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1")
x <- x[!(row.names(x) %in% row.names.remove), ]

x1 <- x %>%
          filter(V1>0.06 | V2>0.06)

x2 <- x %>%
          filter(V1< -0.06 | V2< -0.06) 

x <- rbind(x1, x2, by=0, all=TRUE)
x <- x[!(row.names(x) %in% row.names.remove), ]

biplot(y= dimsetup$docs[,2:3],x= x, col=c("grey","red"),
       xlab = "Dim 2", ylab="Dim 3",expand=2, xlim=c(-0.7,0.9), ylim=c(-0.6,0.99))

#plot dimensions 3 and 4
x <- dimsetup$features[,3:4] %>% as.data.frame()
# row.names.remove <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1")
# x <- x[!(row.names(x) %in% row.names.remove), ]

x1 <- x %>%
          filter(V1>0.06 | V2>0.06)

x2 <- x %>%
          filter(V1< -0.06 | V2< -0.06) 

x <- rbind(x1, x2, by=0, all=TRUE)
x <- x[!(row.names(x) %in% row.names.remove), ]

biplot(y= dimsetup$docs[,3:4],x= x, col=c("grey","red"),
       xlab = "Dim 3", ylab="Dim 4",expand=1, xlim=c(-0.4,0.9), ylim=c(-0.4, 0.8))

#extract
row.names.remove <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1")
dimsetup$features <- dimsetup$features[!(row.names(dimsetup$features) %in% row.names.remove), ]

n.terms <- 10

#extract words in each topic
#topic 1
sort(abs(dimsetup$features[,1]), decreasing = TRUE)[1:n.terms] %>% kable(col.names = NULL, caption = "Main words of topic 1") %>% kable_styling(latex_options = "striped",full_width = FALSE)

#topic 2
t(t(sort(dimsetup$features[, 2], decreasing = TRUE)[c(1:n.terms, nrow(dimsetup$features) -
                                                        c(n.terms:1) + 1)])) %>% kable(col.names = NULL, caption = "Main words of topic 2") %>% kable_styling(latex_options = "striped",full_width = FALSE)
#topic 3
t(t(sort(dimsetup$features[, 3], decreasing = TRUE)[c(1:n.terms, nrow(dimsetup$features) -
                                                        c(n.terms:1) + 1)])) %>% kable(col.names = NULL, caption = "Main words of topic 3") %>% kable_styling(latex_options = "striped",full_width = FALSE)
#topic 4
t(t(sort(dimsetup$features[, 4], decreasing = TRUE)[c(1:n.terms, nrow(dimsetup$features) -
                                                        c(n.terms:1) + 1)])) %>% kable(col.names = NULL, caption = "Main words of topic 4") %>% kable_styling(latex_options = "striped",full_width = FALSE)
```
We repeat the same LSA process but with TF-IDF.

```{r}
tweets.tfidf <- dfm_tfidf(tweet.dfm)
dimsetup <- textmodel_lsa(tweets.tfidf, nd=4)

#analyze the correlation
ns <- apply(tweets.tfidf, 1, sum) # row-sum of the DTM
plot(ns~dimsetup$docs[,1])

#plot dimensions 2 and 3 
x <- dimsetup$features[,2:3] %>% as.data.frame()
row.names.remove <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1", "all")
x <- x[!(row.names(x) %in% row.names.remove), ]

x1 <- x %>%
          filter(V1>0.06 | V2>0.06)

x2 <- x %>%
          filter(V1< -0.06 | V2< -0.06) 

x <- rbind(x1, x2, by=0, all=TRUE)
x <- x[!(row.names(x) %in% row.names.remove), ]

biplot(y= dimsetup$docs[,2:3],x= x, col=c("grey","red"),
       xlab = "Dim 2", ylab="Dim 3", expand = 1)

#plot dimensions 3 and 4
x <- dimsetup$features[,3:4] %>% as.data.frame()
# row.names.remove <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1")
# x <- x[!(row.names(x) %in% row.names.remove), ]

x1 <- x %>%
          filter(V1>0.06 | V2>0.06)

x2 <- x %>%
          filter(V1< -0.06 | V2< -0.06) 

x <- rbind(x1, x2, by=0, all=TRUE) 
x <- x[!(row.names(x) %in% row.names.remove), ]

biplot(y= dimsetup$docs[,3:4],x= x, col=c("grey","red"),
       xlab = "Dim 3", ylab="Dim 4",expand=1)

#extract
row.names.remove <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1", "xdzz", "jill", "eoxt", "usmca", "ofa", "uoivh")
dimsetup$features <- dimsetup$features[!(row.names(dimsetup$features) %in% row.names.remove), ]

n.terms <- 10

#extract words in each topic
#topic 1
sort(abs(dimsetup$features[,1]), decreasing = TRUE)[1:n.terms] %>% kable(col.names = NULL, caption = "Main words of topic 1") %>% kable_styling(latex_options = "striped",full_width = FALSE)

#topic 2
t(t(sort(dimsetup$features[, 2], decreasing = TRUE)[c(1:n.terms, nrow(dimsetup$features) -
                                                        c(n.terms:1) + 1)])) %>% kable(col.names = NULL, caption = "Main words of topic 2") %>% kable_styling(latex_options = "striped",full_width = FALSE)
#topic 3
t(t(sort(dimsetup$features[, 3], decreasing = TRUE)[c(1:n.terms, nrow(dimsetup$features) -
                                                        c(n.terms:1) + 1)])) %>% kable(col.names = NULL, caption = "Main words of topic 3") %>% kable_styling(latex_options = "striped",full_width = FALSE)
#topic 4
t(t(sort(dimsetup$features[, 4], decreasing = TRUE)[c(1:n.terms, nrow(dimsetup$features) -
                                                        c(n.terms:1) + 1)])) %>% kable(col.names = NULL, caption = "Main words of topic 4") %>% kable_styling(latex_options = "striped",full_width = FALSE)


```

### LDA

```{r message=FALSE, warning=FALSE}
library(topicmodels)

K <- 8
tweet.dtm <- convert(tweet.dfm, to = "topicmodels")

lda <- LDA(tweet.dtm, k = K) 

terms <- terms(lda, 10)[-1,] #remove the first row composed of https word
terms %>% kable(caption = "The words most associated with the topics") %>% kable_styling(latex_options = "striped",full_width = FALSE)

topics(lda, 1) %>% kable(col.names = NULL, caption = "Topics most associated with each document") %>% kable_styling(latex_options = "striped", full_width = FALSE)

## show the betas of each document
beta.td <- tidy(lda, matrix = "beta") # beta's are turned to proba scales
beta.td 

badwords <- c("u","t","co ","https","http","s","amp","re","m","ll", "co", "we", "obama1")
beta.td <- beta.td[ !grepl(paste(badwords, collapse="|"), beta.td$term),]




#describe the topics with their most associated terms
beta.top.terms <- beta.td %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)


beta.top.terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap( ~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics with their most associated terms") + ylab("Beta") +
  xlab("Terms") 

## describes the topics in each documents
gamma.td <- tidy(lda, matrix = "gamma")
gamma.td %>%
  ggplot(aes(document, gamma, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() + labs(title = "Topics with the most associated documents") + ylab("Gamma") +
  xlab("Documents") 



```



<!-- #word embedding -->
<!-- ```{r message=FALSE, warning=FALSE} -->
<!-- corpus_final <- read_csv("data supervised_L/corpus_final.csv") -->
<!-- corpus_final <- corpus(corpus_final$text, corpus_final$screen_name) -->

<!-- tweet.cp <- corpus_final -->
<!-- tweet.tk <- tokens(tweet.cp, -->
<!--                    remove_punct = TRUE, -->
<!--                    remove_symbols = TRUE, -->
<!--                    remove_numbers = TRUE) %>% tokens_tolower() %>% -->
<!--   tokens_replace(pattern=hash_lemmas$token, replacement = hash_lemmas$lemma) %>% -->
<!--   tokens_remove(pattern = c("s", "amp", "de","la", "en", "t","re","gsgsgh", -->
<!--                             "u","t","co ","https","http","s","amp","re","m","ll", "co", "we", stopwords("english")))  -->




<!-- tweet.coo <- fcm(tweet.tk, context="window", window = 5, tri=FALSE)  -->

<!-- library(text2vec) -->
<!-- p <- 2 # word embedding dimension -->
<!-- tweet.glove <- GlobalVectors$new(rank = p, x_max = 10) # x_max is a needed technical option -->
<!-- tweet.weC <- tweet.glove$fit_transform(tweet.coo) -->
<!-- tweet.we <- t(tweet.glove$components)+tweet.weC -->

<!-- n.w <- apply(dfm(tweet.tk),2,sum) ## compute the number of times ech term is used -->
<!-- index <- order(n.w, decreasing = TRUE)[1:60] # select the row-number corresponding to the 50 largest n.w -->

<!-- plot(tweet.we[index,], type='n',  xlab="Dim 1", ylab="Dim 2") -->
<!-- text(x=tweet.we[index,], labels=rownames(tweet.we[index,])) -->
<!-- ``` -->

<!-- ```{r} -->

<!-- nd <- length(tweet.tk) # number of documents -->
<!-- tweet.de <- matrix(nr=nd, nc=p) # document embedding matrix (1 document per row) -->
<!-- for (i in 1:nd){ -->
<!--   words_in_i <- tweet.we[tweet.tk[[i]],] -->
<!--   tweet.de[i,] <- apply(words_in_i,2,mean) -->
<!-- } -->
<!-- row.names(tweet.de) <- names(tweet.cp) -->
<!-- ## tweet.de -->

<!-- plot(tweet.de, type='n',  xlab="Dim 1", ylab="Dim 2", main="Centroids") -->
<!-- text(x=tweet.de, labels=rownames(tweet.de)) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- tweet.dtm <- dfm(tweet.tk) -->
<!-- tweet.rwmd.model <- RelaxedWordMoversDistance$new(tweet.dtm, tweet.we) -->
<!-- tweet.rwms <- tweet.rwmd.model$sim2(tweet.dtm) -->
<!-- tweet.rwmd <- tweet.rwmd.model$dist2(tweet.dtm) -->

<!-- tweet.hc <- hclust(as.dist(tweet.rwmd)) -->
<!-- plot(tweet.hc, cex=0.8) -->
<!-- ``` -->


# Supervised learning

In this part, we will use the whole set of data which includes the tweets before and after the election. We would like to predict the person who wrote those tweets and also his political party. 

At the beginning, we add the variable corresponding to the political party of the tweet's writer. We also create a new varible with the abbreviation of the name of the tweet's writers. Then, we create a corpus and clean it. We use the lemmatization method in the tokenisation process. 

```{r include=FALSE}
f <- file.path(here("data supervised_L/"), c("biden_after.csv","kamala_after.csv", "trump_after.csv", "vp_after.csv", "obama_after.csv", "aoc_after.csv"))
d <- lapply(f, read.csv)

# d <- Map(cbind, d, name_abb = c("Biden", "Kamala", "Trump", "VP", "obama", "aoc"))

tweet_all <- rbind(d[[1]], d[[2]], d[[3]], d[[4]],d[[5]],d[[6]])

tweet_all <- tweet_all %>% select(screen_name, created_at, text, source, display_text_width, favorite_count, retweet_count)

#add the political party of the author of a tweet to the dataset
tweet_all <- tweet_all %>% mutate(party = case_when(grepl(c("realDonaldTrump|VP"), screen_name) ~ "republican", 
                                    grepl(c("BarackObama|JoeBiden|KamalaHarris|AOC"), screen_name) ~ "democrate"))

tweet_all$text <- as.character(tweet_all$text) #transform text column into character

tweets.corpus <- corpus(tweet_all)

tweets.corpus <- gsub('\\b\\w{1,2}\\b','', tweets.corpus) #remove tokens whose length is smaller than 3

# library(lexicon)
# library(qdapRegex)

#tokenisation
tweets.tokens <- tokens(
  tweets.corpus,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_url = TRUE,
  what = "word1")

 tweets.tokens <- tweets.tokens %>% tokens_replace(pattern = hash_lemmas$token, replacement =
                                           hash_lemmas$lemma)  #use the lemmatization 

 
tweets.tokens <- tweets.tokens %>% tokens_tolower() %>% tokens_remove(stopwords("english")) %>% tokens_remove(c("https", "t.co", "http", "amp"))
 
tweets.tokens <- tweets.tokens %>%  tokens_remove(pattern = "(?<=\\d{1,9})\\w+", valuetype = "regex" ) #remove tokens containing numbers

tweets.tokens <- tweets.tokens %>% tokens_subset(ntoken(tweets.tokens) > 2) #remove sentences with less than 3 tokens
```

### Word embedding

We create a words vector representation using the GloVe method. To do it, we first need to compute the co-occurence matrix. 

```{r}
tweets_coo <- fcm(tweets.tokens, context = "window", window = 5, tri = FALSE)

library(text2vec)
p <- 2 #word embedding dimension
tweets.glove <- GlobalVectors$new(rank = p, x_max = 10) #GloVe method
tweets.we <- tweets.glove$fit_transform(tweets_coo) #central vectors
word_vectors_context <- tweets.glove$components #context vectors
twitter.glove <- tweets.we + t(word_vectors_context) #match central vectors and context vectors

nwords <- apply(dfm(tweets.tokens), 2, sum) #number of times each term is used (frequency)
index <- order(nwords, decreasing = TRUE)[1:100] #100 largest number of words
plot(tweets.we[index,], type ="n", xlab="Dim1", ylab="Dim2", main = "The 100 most frequent words") #plot the 100 most frequent words in the corpus
text(x=tweets.we[index,], labels = rownames(tweets.we[index,]))
```


Because the cluster is completely illegible, we display the 10 most frequent words in 5 clusters. Clusters are computed using the RelaxedWordMoversDistance (RWMD)

```{r}
tweets.dtm <- dfm(tweets.tokens)
tweets.rwmd <- RelaxedWordMoversDistance$new(tweets.dtm, tweets.we)

tweets.rwmd.dist <- tweets.rwmd$dist2(tweets.dtm)
tweets.hc <- hclust(as.dist(tweets.rwmd.dist))   

memb <- cutree(tweets.hc, k = 5) #to have a significant clustering, we reduce their numbers to 5 

tweets.dtm[memb == 1,]
data.frame(Clust.1 = names(sort(apply(tweets.dtm[memb == 1,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.2 = names(sort(apply(tweets.dtm[memb == 2,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.3 = names(sort(apply(tweets.dtm[memb == 3,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.4 = names(sort(apply(tweets.dtm[memb == 4,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.5 = names(sort(apply(tweets.dtm[memb == 5,], 2, sum), decreasing = TRUE)[1:10])) 
```

Below, we repeat the same process but with 25 word embedding dimensions. To illustrate it, we display the 10 most frequent words in 5 clusters. 


```{r}
p <- 25 #word embedding dimension
tweets.glove <- GlobalVectors$new(rank = p, x_max = 10) #GloVe method
tweets.we <- tweets.glove$fit_transform(tweets_coo) #central vectors
word_vectors_context <- tweets.glove$components #context vectors
twitter.glove <- tweets.we + t(word_vectors_context) #match central vectors and context vectors

nwords <- apply(dfm(tweets.tokens), 2, sum) #number of times each term is used (frequency)
index <- order(nwords, decreasing = TRUE)[1:100] #100 largest number of words

ndoc <- length(tweets.tokens) #number of documents in the corpus 
centers <- matrix(nrow = ndoc, ncol = p) #create a matrix for the centroids
for(i in 1:ndoc){ #compute the centroids 
  words_in_i <- twitter.glove[tweets.tokens[[i]],, drop = FALSE]
  centers[i,] <- apply(words_in_i, 2, mean)
}

row.names(centers) <- names(tweets.tokens) #name the columns of the centroid matrix

tweets.dtm <- dfm(tweets.tokens) #TF
tweets.rwmd <- RelaxedWordMoversDistance$new(tweets.dtm, tweets.we)

tweets.rwmd.dist <- tweets.rwmd$dist2(tweets.dtm)
tweets.hc <- hclust(as.dist(tweets.rwmd.dist))

memb <- cutree(tweets.hc, k = 5) #to have a significant clustering, we reduce their numbers to 5 

tweets.dtm[memb == 1,]
data.frame(Clust.1 = names(sort(apply(tweets.dtm[memb == 1,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.2 = names(sort(apply(tweets.dtm[memb == 2,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.3 = names(sort(apply(tweets.dtm[memb == 3,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.4 = names(sort(apply(tweets.dtm[memb == 4,], 2, sum), decreasing = TRUE)[1:10]),
           Clust.5 = names(sort(apply(tweets.dtm[memb == 5,], 2, sum), decreasing = TRUE)[1:10]))
```
As we can see, the clustering seems more significant. For example, cluster 5 links gathers words that seem to be of Spanish origin, cluster 3 links words related to joy (birthday, happy).

### Author of the tweet prediction

We will build different models to predict the author of a tweet (y = screen_name) and compare them. 

1. TF + LSA 

```{r include=FALSE}
y <- factor(docvars(tweets.tokens, "screen_name")) #who wrote the tweet is the variable to predict

tweets.dfm <- dfm(tweets.tokens)
# dim(tweets.dfm)

# library(quanteda.textmodels)
# library(caret)
# library(ranger)

set.seed(2020)
index.tr <- sample(size=round(0.8*length(y)), x=c(1:length(y)), replace=FALSE) #we split the data into a training set and a test set
# df.tr <- df[index.tr,]
# df.te <- df[-index.tr,]

nd.vec <- c(2,5,25,50,100, 500, 1000) #because our matrix is well too big, we apply a reduction dimension technique such as the LSA one

acc.vec <- numeric(length(nd.vec))
for (j in 1:length(nd.vec)){
  tweets.lsa <- textmodel_lsa(tweets.dfm, nd=nd.vec[j])
  df <- data.frame(Class=y, X=tweets.lsa$docs)
  df <- cbind(df, 
            logretweet=log10(docvars(tweets.tokens, c("retweet_count"))),
            length = log(sapply(tweets.tokens, length)))
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  set.seed(2020)
  tweets.fit <- ranger(Class ~ ., #use a random forest
                       data = df.tr)
  pred.te <- predict(tweets.fit, df.te)
  acc.vec[j] <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)$overall[1]
}


acc.vec

plot(acc.vec ~ nd.vec, type='b', main = "LSA on a DTM matrix composed by the word frequency", ylab = "Accuracy", xlab = "Number of LSA dimensions") #500 dimensions has the best accuracy
```

We found an accuracy of 0.6861423. This score is related to a LSA of 500 dimensions. 


2. TF-IDF + LSA

```{r}
tweets.tfidf <- dfm_tfidf(tweets.dfm)

nd.vec <- c(2,5,25,50,100, 500, 1000) #because our matrix is well too big, we apply a reduction dimension technique such as the LSA one

acc.vec <- numeric(length(nd.vec))
for (j in 1:length(nd.vec)){
  tweets.lsa <- textmodel_lsa(tweets.tfidf, nd=nd.vec[j])
  df <- data.frame(Class=y, X=tweets.lsa$docs)
   df <- cbind(df, 
            logretweet=log10(docvars(tweets.tokens, c("retweet_count"))),
            length = log(sapply(tweets.tokens, length)))
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  set.seed(2020)
  tweets.fit <- ranger(Class ~ ., #use a random forest
                       data = df.tr)
  pred.te <- predict(tweets.fit, df.te)
  acc.vec[j] <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)$overall[1]
}

acc.vec
plot(acc.vec ~ nd.vec, type='b', main = "LSA with TF-IDF", ylab = "Accuracy", xlab = "Number of LSA dimensions") #50 dimensions has the best accuracy

```
As we can see, accuracy is better when using TF-IDF with LSA of 50 dimensions (0.7382022). 

3. Word embedding + centroids

We compute the centroids in order to transform the word embedding to a document embedding. 

We start with the two dimensions word embedding from the previous part. 

```{r}
p <- 2 #word embedding dimension
tweets.glove <- GlobalVectors$new(rank = p, x_max = 10) #GloVe method
tweets.we <- tweets.glove$fit_transform(tweets_coo) #central vectors
word_vectors_context <- tweets.glove$components #context vectors
twitter.glove <- tweets.we + t(word_vectors_context) #match central vectors and context vectors

ndoc <- length(tweets.tokens) #number of documents in the corpus 
centers <- matrix(nrow = ndoc, ncol = p) #create a matrix for the centroids
for(i in 1:ndoc){ #compute the centroids 
  words_in_i <- twitter.glove[tweets.tokens[[i]],, drop = FALSE]
  centers[i,] <- apply(words_in_i, 2, mean)
}

row.names(centers) <- names(tweets.tokens) #name the columns of the centroid matrix

plot(x = centers, type ="n", xlab="Dim1", ylab="Dim2", main = "Centroids") #plot the centroids
text(centers, labels = rownames(centers))

```

```{r}
df <- data.frame(Class=y, X=centers)
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]
set.seed(2020)


tweets.fit <- ranger(Class ~ .,
                     data = df.tr)

pred.te <- predict(tweets.fit, df.te)
confusionMatrix(data=pred.te$predictions, reference = df.te$Class)
```
With an accuracy of 0.2764, the cendroids coming from the word embedding part (two dimensions word embedding) are very bad for the prediction model. We could try to use more word embedding dmensions in order to see if we get better results. We set the dimensions of word embedding to 25. 

```{r}
tweets_coo <- fcm(tweets.tokens, context = "window", window = 5, tri = FALSE)
p <- 25 #word embedding dimension
tweets.glove <- GlobalVectors$new(rank = p, x_max = 10) #GloVe method
tweets.we <- tweets.glove$fit_transform(tweets_coo) #central vectors
word_vectors_context <- tweets.glove$components #context vectors
twitter.glove <- tweets.we + t(word_vectors_context) #match central vectors and context vectors

ndoc <- length(tweets.tokens) #number of documents in the corpus 
centers <- matrix(nrow = ndoc, ncol = p) #create a matrix for the centroids
for(i in 1:ndoc){ #compute the centroids 
  words_in_i <- twitter.glove[tweets.tokens[[i]],, drop = FALSE]
  centers[i,] <- apply(words_in_i, 2, mean)
}

row.names(centers) <- names(tweets.tokens) #name the columns of the centroid matrix

df <- data.frame(Class=y, X=centers)
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]

set.seed(2020)
tweets.fit <- ranger(Class ~ ., 
                     data = df.tr)

pred.te <- predict(tweets.fit, df.te)
cm1 <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)

draw_confusion_matrix <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, 'Class1', cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, 'Class2', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, 'Class1', cex=1.2, srt=90)
  text(140, 335, 'Class2', cex=1.2, srt=90)

  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  # text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  # text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  # text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  # text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  # text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  # text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  # text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  # text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  # text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  # text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 60, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 35, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 60, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 35, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  

draw_confusion_matrix(cm1)

```
With 25 dimensions, we get an accuracy of 0.621 which is better than when using only two dimensions in word embedding. We will keep using 25 dimensions in order to limit the computational time for the following.

TF-IDF is doing better. Now, we will try to combine the centroids with TF-IDF in order to see if we can improve accuracy. 

4. Combining centroids with TF-IDF + LSA 


```{r}
tweets.tfidf <- dfm_tfidf(tweets.dfm) #TF-IDF
tweets.lsa <- textmodel_lsa(tweets.tfidf, nd=50) 
df <- data.frame(Class=y, X=tweets.lsa$docs)
df <- cbind(df, 
            logretweet=log10(docvars(tweets.tokens, c("retweet_count"))),
            length = log(sapply(tweets.tokens, length)))
df <- cbind(df, Cent=centers) #add the centroid from word embedding part
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]
set.seed(2020)
tweets.fit <- ranger(Class ~ ., 
                     data = df.tr, 
                     importance = "impurity")
pred.te <- predict(tweets.fit, df.te)
cm2 <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)
draw_confusion_matrix(cm2)

```
The combination of features (TF-IDF + LSA + Centroids) (0.7367) does not surpass the prediction made with the TF-IDF and LSA (0.7382022). 


For the following, we will keep this last combination of features (TF-IDF + LSA + Centroids) to compare the results with different models.


5. Support vector machine (SVM)

```{r}
is.na(df) <- sapply(df, is.infinite) #transform infinite values into NA 
df<- drop_na(df) #remove na values
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]

train_control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"

set.seed(2020)
fit_svm <- train(
  form = Class ~ .,
  data = df.tr,
  trControl = train_control,
  tuneLength = 5,
  method = "svmRadial",
  preProcess = c("center","scale"),
  metric = metric,
  na.action=na.exclude
)

pred.te <- predict(tweets.fit, df.te)
cm3 <-  confusionMatrix(data=pred.te$predictions, reference = df.te$Class)
draw_confusion_matrix(cm3)
```
The SVM model, with an accuracy of 0.8472, is doing a great job in comparison to the random forest model.

6. Neural network (NN)

In order to avoid overfitting, we will use a weight decay to penalise the largest weights. We will also tune the size of the neural networks to find the opimal one.

We will use a five cross-validation to subset the training set (into a validation set) in order to asses how well the model will generalize to the test set.

```{r}
hp_nn <- expand.grid(size = 2:10,
                     decay = seq(0, 0.5, 0.05))

train_control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"

set.seed(2020)
tweets.fit <- train(
  form = Class ~ .,
  data = df.tr,
  tuneGrid = hp_nn,
  method = "nnet",
  trControl = train_control,
  metric = metric,
  na.action=na.exclude)

pred.te <- predict(tweets.fit, newdata = df.te)
cm4 <- confusionMatrix(data=pred.te, reference = df.te$Class)
draw_confusion_matrix(cm4)

```
The accuracy of 0.671 is really disappointing. The neural network model should not be used to predict the author of a tweet. 

7. Linear discriminant analysis (LDA)

```{r}
train_control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"

set.seed(2020)
tweets.fit <- train(
  form = Class ~ .,
  data = df.tr,
  method = "lda",
  trControl = train_control,
  metric = metric,
  na.action=na.exclude)


pred.te <- predict(tweets.fit, newdata = df.te)
cm5 <- confusionMatrix(data=pred.te, reference = df.te$Class)
draw_confusion_matrix(cm5)
```

Just like the neural network model, the LDA is not good enough (0.68). 

### Political party prediction

Then, we repeat the previous process to predict the political party (y = party).


1. TF + LSA 
```{r include=FALSE}
#we add new features for our model
y <- factor(docvars(tweets.tokens, "party")) #political party is the variable to predict
tweets.dfm <- dfm(tweets.tokens)

nd.vec <- c(2,5,25,50,100, 500, 1000) #because our matrix is well too big, we apply a reduction dimension technique such as the LSA one

acc.vec <- numeric(length(nd.vec))
for (j in 1:length(nd.vec)){
  tweets.lsa <- textmodel_lsa(tweets.dfm, nd=nd.vec[j])
  df <- data.frame(Class=y, X=tweets.lsa$docs)
  df <- cbind(df, 
            logretweet=log10(docvars(tweets.tokens, c("retweet_count"))),
            length = log(sapply(tweets.tokens, length)))
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  set.seed(2020)
  tweets.fit <- ranger(Class ~ ., #use a random forest
                       data = df.tr)
  pred.te <- predict(tweets.fit, df.te)
  acc.vec[j] <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)$overall[1]
}

plot(acc.vec ~ nd.vec, type='b',  main = "LSA on a DTM matrix composed by the word frequency", ylab = "Accuracy", xlab = "Number of LSA dimensions") #50 dimensions has the best accuracy

acc.vec
```
The best accuracy (0.8576779) is found with a LSA of 50 dimensions. 


2. TF-IDF + LSA

```{r}
tweets.tfidf <- dfm_tfidf(tweets.dfm)

nd.vec <- c(2,5,25,50,100, 500, 1000) #because our matrix is well too big, we apply a reduction dimension technique such as the LSA one

acc.vec <- numeric(length(nd.vec))
for (j in 1:length(nd.vec)){
  tweets.lsa <- textmodel_lsa(tweets.tfidf, nd=nd.vec[j])
  df <- data.frame(Class=y, X=tweets.lsa$docs)
   df <- cbind(df, 
            logretweet=log10(docvars(tweets.tokens, c("retweet_count"))),
            length = log(sapply(tweets.tokens, length)))
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  set.seed(2020)
  tweets.fit <- ranger(Class ~ ., #use a random forest
                       data = df.tr)
  pred.te <- predict(tweets.fit, df.te)
  acc.vec[j] <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)$overall[1]
}

acc.vec
plot(acc.vec ~ nd.vec, type='b', main = "LSA with TF-IDF", ylab = "Accuracy", xlab = "Number of LSA dimensions") #50 dimensions has the best accuracy

```
The random forest trained on a TF-IDF with a LSA of 50 dimensions get an accuracy of 0.8928839 which is better than with TF. Therefore, we will continue with the TF-IDF. 

3. Word embedding + centroids

```{r}
p <- 25 #word embedding dimension

tweets.glove <- GlobalVectors$new(rank = p, x_max = 10) #GloVe method
tweets.we <- tweets.glove$fit_transform(tweets_coo) #central vectors
word_vectors_context <- tweets.glove$components #context vectors
twitter.glove <- tweets.we + t(word_vectors_context) #match central vectors and context vectors

ndoc <- length(tweets.tokens) #number of documents in the corpus 
centers <- matrix(nrow = ndoc, ncol = p) #create a matrix for the centroids
for(i in 1:ndoc){ #compute the centroids 
  words_in_i <- twitter.glove[tweets.tokens[[i]],, drop = FALSE]
  centers[i,] <- apply(words_in_i, 2, mean)
}

row.names(centers) <- names(tweets.tokens) #name the columns of the centroid matrix

df <- data.frame(Class=y, X=centers)
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]
set.seed(2020)
tweets.fit <- ranger(Class ~ ., 
                     data = df.tr)
pred.te <- predict(tweets.fit, df.te)
cm6 <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)
draw_confusion_matrix(cm6)

```
The random forest trained on the centroids do quite a good job (0.848). Therefore, centroids can be combined with other features to improve the model. 


4. Combining centroids with TF-IDF + LSA 

```{r}
tweets.tfidf <- dfm_tfidf(tweets.dfm) #TF-IDF
tweets.lsa <- textmodel_lsa(tweets.tfidf, nd=50) 
df <- data.frame(Class=y, X=tweets.lsa$docs)
df <- cbind(df, 
            logretweet=log10(docvars(tweets.tokens, c("retweet_count"))),
            length = log(sapply(tweets.tokens, length)))
df <- cbind(df, Cent=centers) # add the centroid from word embedding part
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]
set.seed(2020)
tweets.fit <- ranger(Class ~ ., 
                     data = df.tr, 
                     importance = "impurity")
pred.te <- predict(tweets.fit, df.te)
cm7 <- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)
draw_confusion_matrix(cm7)

```

With an accuracy of 0.885, we can conclude that centroids do not improve our TF-IDF + LSA model. 

5. Support vector machine (SVM)

```{r}
is.na(df) <- sapply(df, is.infinite) #transform infinite values into NA 
df<- drop_na(df) #remove na values
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]

train_control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"

set.seed(2020)
fit_svm <- train(
  form = Class ~ .,
  data = df.tr,
  trControl = train_control,
  tuneLength = 5,
  method = "svmRadial",
  preProcess = c("center","scale"),
  metric = metric,
  na.action=na.exclude
)

pred.te <- predict(tweets.fit, df.te)
cm8<- confusionMatrix(data=pred.te$predictions, reference = df.te$Class)
draw_confusion_matrix(cm8)
```

SVM is doing a great job with an accuracy of 0.964 In addition, there is a high specificity and a high sensitivity which are quite well balanced.

6. Neural network (NN)

```{r}
hp_nn <- expand.grid(size = 2:10,
                     decay = seq(0, 0.5, 0.05))

train_control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"

set.seed(2020)
tweets.fit <- train(
  form = Class ~ .,
  data = df.tr,
  tuneGrid = hp_nn,
  method = "nnet",
  trControl = train_control,
  metric = metric,
  na.action=na.exclude)

pred.te <- predict(tweets.fit, newdata = df.te)
cm9 <- confusionMatrix(data=pred.te, reference = df.te$Class)
draw_confusion_matrix(cm9)
```

Accuracy = 0.893

7. Linear discriminant analysis (LDA)

```{r}
train_control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"

set.seed(2020)
tweets.fit <- train(
  form = Class ~ .,
  data = df.tr,
  method = "lda",
  trControl = train_control,
  metric = metric,
  na.action=na.exclude)


pred.te <- predict(tweets.fit, newdata = df.te)
cm10 <- confusionMatrix(data=pred.te, reference = df.te$Class)
draw_confusion_matrix(cm10)
```


Accuracy = 0.87
