
```{r setup, include=FALSE}
#ici les données sont avant et après, il y a toujours moyen de les filtrer selon les besoin
f <- file.path(here("data supervised_L/"), c("biden_after.csv","kamala_after.csv", "trump_after.csv", "vp_after.csv", "obama_after.csv", "aoc_after.csv"))
d <- lapply(f, read.csv)
str(d, give.attr = FALSE)

d <- Map(cbind, d, name = c("Biden", "Kamala", "Trump", "VP", "obama", "aoc"))

tweet_all <- rbind(d[[1]], d[[2]], d[[3]], d[[4]],d[[5]],d[[6]])

#j'essaie de rajouter le partie politique des candidats
'%!in%' <- function(x,y)!('%in%'(x,y))
party <- c("realDonaldTrump", "VP")
tweet_all$party <- ifelse((tweet_all$screen_name %in% party) , "republican", 
                         ifelse((tweet_all$screen_name %!in% party) , "democrate"))

tweet_all$Category<-ifelse(tweet_all$screen_name = "realDonaldTrump" | "VP","Good","Bad")

tweets.corpus <- corpus(tweet_all)


tweets.tokens <- tokens(tweets.corpus, 
                        remove_punct = TRUE, 
                        remove_symbols = TRUE, 
                        remove_url = TRUE,
                        what="word1")

tweets.tokens <- tokens_tolower(tweets.tokens) %>% tokens_wordstem() %>%
  tokens_remove(stopwords("english")) %>% 
  tokens_subset(ntoken(tweets.tokens) > 2) 

########## à partir de la ça doit être assez similaire aux exos du prof (supervised et unsupervised)
#j'ai pensé qu'on pourrait créer une variable y (partie politique -> prédire le partie)
#on peut aussi bien évidemmetn prédire celui qui à écrit le tweet ou d'autre variable 
#on peut aussi essayer de mieux nettoyer le mots inutils voir si ça améliore la prédiciton 

names(tweet_all) #les diff variable du corpus
y <- factor(docvars(tweets.tokens, "screen_name")) #ici y = celui qui à écrit le tweet 

tweets.dfm <- dfm(tweets.tokens)
dim(tweets.dfm)

library(quanteda.textmodels)
#essayer différente dim

tweets.lsa <- textmodel_lsa(tweets.dfm, nd=25)
head(tweets.lsa$docs)

df <- data.frame(Class=y, X=tweets.lsa$docs)
index.tr <- sample(size=round(0.8*length(y)), x=c(1:length(y)), replace=FALSE)
df.tr <- df[index.tr,]
df.te <- df[-index.tr,]
library(ranger)
tweets.fit <- ranger(Class ~ ., 
                     data = df.tr)
pred.te <- predict(tweets.fit, df.te)

library(caret)
confusionMatrix(data=pred.te$predictions, reference = df.te$Class)
```





# Analysis GAETAN
```{r eval=FALSE, include=FALSE}


f <- file.path(here("data_before/"), c("BIDEN_all_tweet.csv","KAMALA_all_tweet.csv", "TRUMP_all_tweet.csv", "VP_all_tweet.csv"))
d <- lapply(f, read.csv)
str(d, give.attr = FALSE)

d <- Map(cbind, d, name = c("Biden", "Kamala", "Trump", "VP"))

test<- rbind(d[[1]], d[[2]], d[[3]], d[[4]])
test<- tibble(test)


test2 <- as.character(as.vector(test[,1])) 
tweets.corpus <- corpus(test2)

tweets.tokens <- tokens(tweets.corpus, 
                        remove_punct = TRUE, 
                        remove_symbols = TRUE, 
                        remove_url = TRUE,
                        what="word1") ## option for removing hastags and tags symbols (@, #, etc.)

tweets.tokens <- tokens_tolower(tweets.tokens) %>% tokens_wordstem() %>%
    tokens_remove(stopwords("english")) %>% 
    tokens_subset(ntoken(tweets.tokens) > 2) # removes tweets with 2 or fewer tokens


y <- factor(docvars(tweets.tokens, "handle"))

tweets.dfm <- dfm(tweets.tokens)
dim(tweets.dfm)

```